{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading nlp-getting-started, 607343 bytes compressed\n",
      "[==================================================] 607343 bytes downloadedFailed to load https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/17777/869809/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20241005%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20241005T161812Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=26ee88f8f2f34baff916b88c1cab3e950cd6fedc586bc53892d3fe05a827f41b82702449d4140ccc51a305f44cb0279e010a2a9622bb452008243d8996a6bde90c97d76509cd4d389a0f112b9ecc95e52fe911d861fb725bd5bfa98fc80db10f713709f3a9a8214462f30208758c218dd17bc5e68e334241a77d642de4ba98119a7a727746e33f40c8314d13741f0da0f9006ba8eaa3f68161f4c8ca75ec5a27b7d27cf217ea429027e4b09c56642dcd3895f04a022ccd2e99ae9c799ed21e659cb30a2adfa45688c3d80669dd35bc872e13520244a8832ee611070f691e943f2de9d6979be8ae865cc64c694530f67698273ebb4e5870b98e285f0e2f8ec9ca to path kaggle/input/nlp-getting-started\n",
      "Data source import complete.\n"
     ]
    }
   ],
   "source": [
    "# This cell is to run Kaggle data sources import in a custom juptyer lab \n",
    "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
    "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
    "# THEN FEEL FREE TO DELETE THIS CELL.\n",
    "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
    "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
    "# NOTEBOOK.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from tempfile import NamedTemporaryFile\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import unquote, urlparse\n",
    "from urllib.error import HTTPError\n",
    "from zipfile import ZipFile\n",
    "import tarfile\n",
    "import shutil\n",
    "\n",
    "CHUNK_SIZE = 40960\n",
    "DATA_SOURCE_MAPPING = 'nlp-getting-started:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F17777%2F869809%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20241005%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20241005T161812Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D26ee88f8f2f34baff916b88c1cab3e950cd6fedc586bc53892d3fe05a827f41b82702449d4140ccc51a305f44cb0279e010a2a9622bb452008243d8996a6bde90c97d76509cd4d389a0f112b9ecc95e52fe911d861fb725bd5bfa98fc80db10f713709f3a9a8214462f30208758c218dd17bc5e68e334241a77d642de4ba98119a7a727746e33f40c8314d13741f0da0f9006ba8eaa3f68161f4c8ca75ec5a27b7d27cf217ea429027e4b09c56642dcd3895f04a022ccd2e99ae9c799ed21e659cb30a2adfa45688c3d80669dd35bc872e13520244a8832ee611070f691e943f2de9d6979be8ae865cc64c694530f67698273ebb4e5870b98e285f0e2f8ec9ca'\n",
    "\n",
    "KAGGLE_INPUT_PATH='kaggle/input'\n",
    "KAGGLE_WORKING_PATH='kaggle/working'\n",
    "KAGGLE_SYMLINK='kaggle'\n",
    "\n",
    "# os.makedirs(KAGGLE_SYMLINK)\n",
    "# os.makedirs(KAGGLE_INPUT_PATH, 0o777)\n",
    "# os.makedirs(KAGGLE_WORKING_PATH, 0o777)\n",
    "\n",
    "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
    "    directory, download_url_encoded = data_source_mapping.split(':')\n",
    "    download_url = unquote(download_url_encoded)\n",
    "    filename = urlparse(download_url).path\n",
    "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
    "    try:\n",
    "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
    "            total_length = fileres.headers['content-length']\n",
    "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
    "            dl = 0\n",
    "            data = fileres.read(CHUNK_SIZE)\n",
    "            while len(data) > 0:\n",
    "                dl += len(data)\n",
    "                tfile.write(data)\n",
    "                done = int(50 * dl / int(total_length))\n",
    "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
    "                sys.stdout.flush()\n",
    "                data = fileres.read(CHUNK_SIZE)\n",
    "            if filename.endswith('.zip'):\n",
    "              with ZipFile(tfile) as zfile:\n",
    "                zfile.extractall(destination_path)\n",
    "            else:\n",
    "              with tarfile.open(tfile.name) as tarfile:\n",
    "                tarfile.extractall(destination_path)\n",
    "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
    "    except HTTPError as e:\n",
    "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
    "        continue\n",
    "    except OSError as e:\n",
    "        print(f'Failed to load {download_url} to path {destination_path}')\n",
    "        continue\n",
    "\n",
    "print('Data source import complete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP with Disaster Tweets \n",
    "\n",
    "NLP - or *Natural Language Processing* - is shorthand for a wide array of techniques designed to help machines learn from text. Natural Language Processing powers everything from chatbots to search engines, and is used in diverse tasks like sentiment analysis and machine translation. \n",
    "\n",
    "## Project Description\n",
    "The primary goal of this project is to build a machine learning model that predicts which Tweets are about real disasters and which one’s aren’t. This is a classic case of binary classification problem. \n",
    "\n",
    "## Data Description\n",
    "The dataset is taken from the Kaggle competition [Natural Language Processing with Disaster Tweets](https://www.kaggle.com/c/nlp-getting-started). \n",
    "Structure of the data is as follows:\n",
    "- `id` - a unique identifier for each tweet\n",
    "- `text` - the text of the tweet\n",
    "- `location` - the location the tweet was sent from (may be blank)\n",
    "- `keyword` - a particular keyword from the tweet (may be blank)\n",
    "- `target` - in train.csv only, this denotes whether a tweet is about a real disaster (1) or not (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading the data from the CSV files\n",
    "train_df = pd.read_csv(\"./kaggle/input/nlp-getting-started/train.csv\")\n",
    "test_df = pd.read_csv(\"./kaggle/input/nlp-getting-started/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the first few rows of the training data\n",
    "train_df.head()\n",
    "\n",
    "# Print the first tweet\n",
    "train_df[\"text\"].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing \n",
    "Check for missing values and handle them accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id             0\n",
      "keyword       61\n",
      "location    2533\n",
      "text           0\n",
      "target         0\n",
      "dtype: int64\n",
      "id             0\n",
      "keyword       26\n",
      "location    1105\n",
      "text           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the training data\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "# Check for missing values in the test data\n",
    "print(test_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values in the training and test data accordingly\n",
    "train_df[\"keyword\"] = train_df[\"keyword\"].fillna(\"missing\")\n",
    "train_df[\"location\"] = train_df[\"location\"].fillna(\"missing\")\n",
    "test_df[\"keyword\"] = test_df[\"keyword\"].fillna(\"missing\")\n",
    "test_df[\"location\"] = test_df[\"location\"].fillna(\"missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the distribution of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the distribution of the target variable\n",
    "sns.countplot(x='target', data=train_df)\n",
    "plt.title('Distribution of Target Variable')\n",
    "plt.xlabel('Target')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "### Sentiment Analysis\n",
    "We will use the `TextBlob` library to perform sentiment analysis on the tweets. This will help us in understanding the sentiment of the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>0.10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>-0.01875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  Our Deeds are the Reason of this #earthquake M...    0.00000\n",
       "1             Forest fire near La Ronge Sask. Canada    0.10000\n",
       "2  All residents asked to 'shelter in place' are ...   -0.01875\n",
       "3  13,000 people receive #wildfires evacuation or...    0.00000\n",
       "4  Just got sent this photo from Ruby #Alaska as ...    0.00000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Function to get the sentiment of a tweet\n",
    "def get_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity\n",
    "\n",
    "# Apply the function to the text column in the training and test data\n",
    "train_df['sentiment'] = train_df['text'].apply(get_sentiment)\n",
    "test_df['sentiment'] = test_df['text'].apply(get_sentiment)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "train_df[['text', 'sentiment']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization \n",
    "We will use the `TfidfVectorizer` to convert the text data into numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape:  (7613, 21637)\n",
      "Test Data Shape:  (3263, 21637)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the TfidfVectorizer\n",
    "tfidf_vectorizer = feature_extraction.text.TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the training data\n",
    "train_tfidf_vectors = tfidf_vectorizer.fit_transform(train_df[\"text\"])\n",
    "\n",
    "# Transform the test data\n",
    "test_tfidf_vectors = tfidf_vectorizer.transform(test_df[\"text\"])\n",
    "\n",
    "# Display the shape of the resulting vectors\n",
    "print(\"Training Data Shape: \",train_tfidf_vectors.shape)\n",
    "print(\"Test Data Shape: \", test_tfidf_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building \n",
    "### 1. Model Architecture with TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Model F1 Scores:  [0.62372881 0.59836512 0.68049793]\n",
      "TF-IDF Model Average F1 Score:  0.6341972871621098\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90      4342\n",
      "           1       0.94      0.78      0.85      3271\n",
      "\n",
      "    accuracy                           0.88      7613\n",
      "   macro avg       0.90      0.87      0.88      7613\n",
      "weighted avg       0.89      0.88      0.88      7613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the logistic regression model\n",
    "logistic_regression_model = linear_model.LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model using the training data\n",
    "logistic_regression_model.fit(train_tfidf_vectors, train_df[\"target\"])\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "tfidf_scores = model_selection.cross_val_score(logistic_regression_model, train_tfidf_vectors, train_df[\"target\"], cv=3, scoring=\"f1\")\n",
    "print(\"TF-IDF Model F1 Scores: \", tfidf_scores)\n",
    "print(\"TF-IDF Model Average F1 Score: \", tfidf_scores.mean())\n",
    "\n",
    "# Print the classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(train_df[\"target\"], logistic_regression_model.predict(train_tfidf_vectors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Simple RNN Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "119/119 [==============================] - 9s 60ms/step - loss: 0.5282 - accuracy: 0.7353\n",
      "Epoch 2/5\n",
      "119/119 [==============================] - 4s 32ms/step - loss: 0.3533 - accuracy: 0.8533\n",
      "Epoch 3/5\n",
      "119/119 [==============================] - 2s 15ms/step - loss: 0.2849 - accuracy: 0.8856\n",
      "Epoch 4/5\n",
      "119/119 [==============================] - 2s 13ms/step - loss: 0.2428 - accuracy: 0.9057\n",
      "Epoch 5/5\n",
      "119/119 [==============================] - 1s 11ms/step - loss: 0.1960 - accuracy: 0.9254\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.1328 - accuracy: 0.9567\n",
      "RNN Model Loss:  0.13276198506355286\n",
      "RNN Model Accuracy:  0.9566531181335449\n",
      "RNN Model F1 Score:  0.9566531181335449\n"
     ]
    }
   ],
   "source": [
    "# Prepare RNN model \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Tokenize the text data\n",
    "# Prepare RNN model input using the sentiment scores\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(train_df[\"text\"])\n",
    "X_train_rnn = tokenizer.texts_to_sequences(train_df[\"text\"])\n",
    "X_val_rnn = tokenizer.texts_to_sequences(test_df[\"text\"])\n",
    "\n",
    "# Build RNN Model\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(Embedding(input_dim=5000, output_dim=128, input_length=100))\n",
    "model_rnn.add(LSTM(128, return_sequences=False))\n",
    "model_rnn.add(Dense(1, activation='sigmoid'))\n",
    "model_rnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train RNN Model\n",
    "model_rnn.fit(pad_sequences(X_train_rnn, maxlen=100), train_df[\"target\"], epochs=5, batch_size=64)\n",
    "\n",
    "# Evaluate RNN Model\n",
    "rnn_scores = model_rnn.evaluate(pad_sequences(X_train_rnn, maxlen=100), train_df[\"target\"])\n",
    "print(\"RNN Model Loss: \", rnn_scores[0])\n",
    "print(\"RNN Model Accuracy: \", rnn_scores[1])\n",
    "print(\"RNN Model F1 Score: \", 2 * (rnn_scores[1] * rnn_scores[1]) / (rnn_scores[1] + rnn_scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. LSTM Model\n",
    "LTSM (Long Short Term Memory) is a type of RNN that is capable of learning long-term dependencies. It is designed to avoid the long-term dependency problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "119/119 [==============================] - 10s 66ms/step - loss: 0.5276 - accuracy: 0.7340\n",
      "Epoch 2/5\n",
      "119/119 [==============================] - 3s 22ms/step - loss: 0.3521 - accuracy: 0.8558\n",
      "Epoch 3/5\n",
      "119/119 [==============================] - 2s 19ms/step - loss: 0.2885 - accuracy: 0.8853\n",
      "Epoch 4/5\n",
      "119/119 [==============================] - 2s 14ms/step - loss: 0.2385 - accuracy: 0.9086\n",
      "Epoch 5/5\n",
      "119/119 [==============================] - 2s 13ms/step - loss: 0.1952 - accuracy: 0.9275\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.1417 - accuracy: 0.9546\n",
      "LSTM Model Loss:  0.14174813032150269\n",
      "LSTM Model Accuracy:  0.9545513987541199\n",
      "LSTM Model F1 Score:  0.9545513987541199\n"
     ]
    }
   ],
   "source": [
    "# Build the LTSM model\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(input_dim=5000, output_dim=128, input_length=100))\n",
    "model_lstm.add(LSTM(128, return_sequences=False))\n",
    "model_lstm.add(Dense(1, activation='sigmoid'))\n",
    "model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the LSTM model\n",
    "model_lstm.fit(pad_sequences(X_train_rnn, maxlen=100), train_df[\"target\"], epochs=5, batch_size=64)\n",
    "\n",
    "# Evaluate the LSTM model\n",
    "lstm_scores = model_lstm.evaluate(pad_sequences(X_train_rnn, maxlen=100), train_df[\"target\"])\n",
    "print(\"LSTM Model Loss: \", lstm_scores[0])\n",
    "print(\"LSTM Model Accuracy: \", lstm_scores[1])\n",
    "print(\"LSTM Model F1 Score: \", 2 * (lstm_scores[1] * lstm_scores[1]) / (lstm_scores[1] + lstm_scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Bi-directional LSTM Model\n",
    "Bi-directional LSTM is a type of LSTM that is capable of capturing the context from both the past and the future, whuch captures the context from both directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "119/119 [==============================] - 11s 68ms/step - loss: 0.5497 - accuracy: 0.7176\n",
      "Epoch 2/5\n",
      "119/119 [==============================] - 4s 35ms/step - loss: 0.3585 - accuracy: 0.8513\n",
      "Epoch 3/5\n",
      "119/119 [==============================] - 3s 22ms/step - loss: 0.2877 - accuracy: 0.8887\n",
      "Epoch 4/5\n",
      "119/119 [==============================] - 2s 20ms/step - loss: 0.2427 - accuracy: 0.9077\n",
      "Epoch 5/5\n",
      "119/119 [==============================] - 2s 15ms/step - loss: 0.1994 - accuracy: 0.9238\n",
      "238/238 [==============================] - 2s 5ms/step - loss: 0.1434 - accuracy: 0.9519\n",
      "Bidirectional LSTM Model Loss:  0.14339514076709747\n",
      "Bidirectional LSTM Model Accuracy:  0.9519243240356445\n",
      "Bidirectional LSTM Model F1 Score:  0.9519243240356445\n"
     ]
    }
   ],
   "source": [
    "# Build the Bidirectional LSTM model \n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "model_bilstm = Sequential()\n",
    "model_bilstm.add(Embedding(input_dim=5000, output_dim=128, input_length=100))\n",
    "model_bilstm.add(Bidirectional(LSTM(128, return_sequences=False)))\n",
    "model_bilstm.add(Dense(1, activation='sigmoid'))\n",
    "model_bilstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the Bidirectional LSTM model\n",
    "model_bilstm.fit(pad_sequences(X_train_rnn, maxlen=100), train_df[\"target\"], epochs=5, batch_size=64)\n",
    "\n",
    "# Evaluate the Bidirectional LSTM model\n",
    "bilstm_scores = model_bilstm.evaluate(pad_sequences(X_train_rnn, maxlen=100), train_df[\"target\"])\n",
    "print(\"Bidirectional LSTM Model Loss: \", bilstm_scores[0])\n",
    "print(\"Bidirectional LSTM Model Accuracy: \", bilstm_scores[1])\n",
    "print(\"Bidirectional LSTM Model F1 Score: \", 2 * (bilstm_scores[1] * bilstm_scores[1]) / (bilstm_scores[1] + bilstm_scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. GRU Model\n",
    "GRU (Gated Recurrent Unit) is a type of RNN that is similar to LSTM, but has fewer parameters than LSTM, as it lacks an output gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "119/119 [==============================] - 10s 67ms/step - loss: 0.5374 - accuracy: 0.7239\n",
      "Epoch 2/5\n",
      "119/119 [==============================] - 3s 24ms/step - loss: 0.3459 - accuracy: 0.8554\n",
      "Epoch 3/5\n",
      "119/119 [==============================] - 2s 18ms/step - loss: 0.2780 - accuracy: 0.8876\n",
      "Epoch 4/5\n",
      "119/119 [==============================] - 1s 12ms/step - loss: 0.2183 - accuracy: 0.9169\n",
      "Epoch 5/5\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 0.1742 - accuracy: 0.9355\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1341 - accuracy: 0.9574\n",
      "GRU Model Loss:  0.1341199427843094\n",
      "GRU Model Accuracy:  0.9574412107467651\n",
      "GRU Model F1 Score:  0.9574412107467651\n"
     ]
    }
   ],
   "source": [
    "# Build the GRU model\n",
    "from tensorflow.keras.layers import GRU\n",
    "model_gru = Sequential()\n",
    "model_gru.add(Embedding(input_dim=5000, output_dim=128, input_length=100))\n",
    "model_gru.add(GRU(128, return_sequences=False))\n",
    "model_gru.add(Dense(1, activation='sigmoid'))\n",
    "model_gru.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the GRU model\n",
    "model_gru.fit(pad_sequences(X_train_rnn, maxlen=100), train_df[\"target\"], epochs=5, batch_size=64)\n",
    "\n",
    "# Evaluate the GRU model\n",
    "gru_scores = model_gru.evaluate(pad_sequences(X_train_rnn, maxlen=100), train_df[\"target\"])\n",
    "print(\"GRU Model Loss: \", gru_scores[0])\n",
    "print(\"GRU Model Accuracy: \", gru_scores[1])\n",
    "print(\"GRU Model F1 Score: \", 2 * (gru_scores[1] * gru_scores[1]) / (gru_scores[1] + gru_scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "### Summary of the results obtained from different models.\n",
    "\n",
    "In this project, we explored various machine learning models to predict whether a tweet is about a real disaster or not. Below are the results obtained from different models:\n",
    "\n",
    "1. **Logistic Regression with TF-IDF Features:**\n",
    "    - **F1 Scores:** [0.6237, 0.5984, 0.6805]\n",
    "    - **Average F1 Score:** 0.6342\n",
    "    - **Classification Report:**\n",
    "      - Precision, Recall, and F1-Score metrics were calculated for both classes (0 and 1).\n",
    "\n",
    "2. **Simple RNN Model:**\n",
    "    - **Loss:** 0.1328\n",
    "    - **Accuracy:** 0.9567\n",
    "    - **F1 Score:** 0.9567\n",
    "\n",
    "3. **LSTM Model:**\n",
    "    - **Loss:** 0.1417\n",
    "    - **Accuracy:** 0.9546\n",
    "    - **F1 Score:** 0.9546\n",
    "\n",
    "4. **Bi-directional LSTM Model:**\n",
    "    - **Loss:** 0.1434\n",
    "    - **Accuracy:** 0.9519\n",
    "    - **F1 Score:** 0.9519\n",
    "\n",
    "5. **GRU Model:**\n",
    "    - **Loss:** 0.1341\n",
    "    - **Accuracy:** 0.9574\n",
    "    - **F1 Score:** 0.9574\n",
    "\n",
    "From the results, we can observe that the GRU model performed the best in terms of accuracy and F1 score, followed closely by the Simple RNN model. The logistic regression model with TF-IDF features also provided decent results but was outperformed by the neural network models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on the Test Data\n",
    "Finally, we will make predictions on the test data using the best performing model and submit the predictions to Kaggle to get the final score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20/102 [====>.........................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 3ms/step\n",
      "Submission CSV file generated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data using the best performing model (GRU model)\n",
    "test_predictions = model_gru.predict(pad_sequences(X_val_rnn, maxlen=100))\n",
    "\n",
    "# Convert predictions to binary values (0 or 1)\n",
    "test_predictions_binary = (test_predictions > 0.5).astype(int)\n",
    "\n",
    "# Create a submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'target': test_predictions_binary.flatten()\n",
    "})\n",
    "\n",
    "# Save the submission DataFrame to a CSV file\n",
    "submission_df.to_csv('~/submission.csv', index=False)\n",
    "\n",
    "print(\"Submission CSV file generated successfully.\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m125"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 869809,
     "sourceId": 17777,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 29844,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
